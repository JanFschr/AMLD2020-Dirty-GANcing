{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional GAN\n",
    "\n",
    "**Purpose**: This notebook provides a walk through the process of training a Conditional GAN to generate digits on the MNIST dataset. Refer to the paper https://arxiv.org/abs/1411.1784 for a full detailed explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.pylab import plt\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variable declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PARAMETERS = {'batch_size': 128,\n",
    "                    'num_classes': 10,\n",
    "                    'img_shape': (1,28,28),\n",
    "                    'epochs': 200,\n",
    "                    'learning_rate': 0.0002}\n",
    "\n",
    "MODEL_HYPERPARAMETERS = {'generator_latent_dim': 100}\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size,\n",
    "                   img_shape):\n",
    "    \n",
    "    img_size = img_shape[1:]\n",
    "    \n",
    "    dataset = datasets.MNIST(root='./data/MNIST',\n",
    "                             train=True,\n",
    "                             download=True,\n",
    "                             transform=transforms.Compose([transforms.Resize(img_size),\n",
    "                                                           transforms.ToTensor(),\n",
    "                                                           transforms.Normalize([0.5], [0.5])]))\n",
    "    \n",
    "    return torch.utils.data.DataLoader(dataset,\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_dataloader(TRAIN_PARAMETERS['batch_size'],\n",
    "                            TRAIN_PARAMETERS['img_shape'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative Adversarial Nets consist on two components competing against each other in a min-max game. These models are:\n",
    "\n",
    "- **Discriminator:** Estimates the probability of a sample coming from the training data or not.\n",
    "- **Generator:** Captures the data distribution generating samples accordingly.\n",
    "\n",
    "Both models play a min max game; the objective of the generator is to fool the discriminator by generating more realistic samples. On the other hand, the discriminator's objective is to identify the samples generated by the generator.\n",
    "\n",
    "Translating these min max game to mathematics, we adjust the Generator's parameters to minimize $log(1-D(G(z))$ and the Discriminator's parameters to minimize $log(D(x))$. Thus, resulting in the following formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/gan_training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Conditional GAN framework adds to both, the input of the discriminator and the generator, some extra information y (note that the aforementioned formula will need to include the condition on y). This extra information often times is the sample class. The model architecture is depicted in the next figure. As it can be seen in the Figure, the generator concatenatese the sampling from z with the input y. Likewise, the discriminator concatenates x with the input y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/conditional_gan_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 img_shape,\n",
    "                 latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(n_classes, n_classes)\n",
    "        self.img_shape = img_shape\n",
    "        \n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim + n_classes, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        gen_input = torch.cat((self.label_emb(labels), noise), -1)\n",
    "        img = self.model(gen_input)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 img_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.label_embedding = nn.Embedding(n_classes,\n",
    "                                            n_classes)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_classes + int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1)\n",
    "        validity = self.model(d_in)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_model(num_classes,\n",
    "                        img_shape,\n",
    "                        latent_dim,\n",
    "                        lr,\n",
    "                        device):\n",
    "    ''' Returns the generator model and its optimizer '''\n",
    "    \n",
    "    generator = Generator(num_classes,\n",
    "                          img_shape,\n",
    "                          latent_dim)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(generator.parameters(),\n",
    "                                 lr=lr)\n",
    "    \n",
    "    return generator.to(device), optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator_model(num_classes,\n",
    "                            img_shape,\n",
    "                            lr,\n",
    "                            device):\n",
    "    ''' Returns the discriminator model and its optimizer '''\n",
    "    \n",
    "    discriminator = Discriminator(num_classes,\n",
    "                                  img_shape)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(discriminator.parameters(),\n",
    "                                 lr=lr)\n",
    "    \n",
    "    return discriminator.to(device), optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator, optimizer_G = get_generator_model(TRAIN_PARAMETERS['num_classes'],\n",
    "                                             TRAIN_PARAMETERS['img_shape'],\n",
    "                                             MODEL_HYPERPARAMETERS['generator_latent_dim'],\n",
    "                                             TRAIN_PARAMETERS['learning_rate'],\n",
    "                                             DEVICE)\n",
    "discriminator, optimizer_D = get_discriminator_model(TRAIN_PARAMETERS['num_classes'],\n",
    "                                                     TRAIN_PARAMETERS['img_shape'],\n",
    "                                                     TRAIN_PARAMETERS['learning_rate'],\n",
    "                                                     DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adversarial_loss():\n",
    "    ''' Returns the adversarial loss '''\n",
    "    \n",
    "    return torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = get_adversarial_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_reconstruction(generator,\n",
    "                        generator_latent_dim,\n",
    "                        n_row,\n",
    "                        epoch_n,\n",
    "                        device):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "\n",
    "    # Create the saving directory\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    # Sample noise\n",
    "    z = torch.FloatTensor(np.random.normal(0, 1, (n_row ** 2, generator_latent_dim))).to(device)\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
    "    labels = torch.LongTensor(labels).to(device)\n",
    "    gen_imgs = generator(z, labels)\n",
    "    save_image(gen_imgs.data, \"results/%d.png\" % epoch_n, nrow=n_row, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(loss_dict):\n",
    "    ''' Plots the loss evolution of the discriminator and generator '''\n",
    "    \n",
    "    for component_name, component_loss in loss_dict.items():\n",
    "        \n",
    "        plt.plot(component_loss, label=component_name)\n",
    "    \n",
    "    plt.title('Loss plot')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs,\n",
    "                dataloader,\n",
    "                generator,\n",
    "                optimizer_G,\n",
    "                discriminator,\n",
    "                optimizer_D,\n",
    "                adv_loss,\n",
    "                generator_latent_dim,\n",
    "                n_classes,\n",
    "                device):\n",
    "    ''' Trains the GAN model '''\n",
    "    \n",
    "    model_loss = {'generator': [], 'discriminator': []}\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        running_g_loss = running_d_loss = 0\n",
    "        \n",
    "        for x, y in dataloader:\n",
    "            \n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            batch_size = x.shape[0]\n",
    "            \n",
    "            valid = torch.FloatTensor(batch_size, 1).fill_(1.0).to(device)\n",
    "            fake = torch.FloatTensor(batch_size, 1).fill_(0.0).to(device)\n",
    "        \n",
    "            ## ---------------\n",
    "            ## Train generator\n",
    "            ## ---------------\n",
    "            \n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            # Sample noise and labels\n",
    "            z = torch.FloatTensor(np.random.normal(0, 1, (batch_size, generator_latent_dim))).to(device)\n",
    "            gen_y = torch.LongTensor(np.random.randint(0, n_classes, batch_size)).to(device)\n",
    "            gen_x = generator(z, gen_y)\n",
    "\n",
    "            validity = discriminator(gen_x, gen_y)\n",
    "            g_loss = adv_loss(validity, valid)\n",
    "            \n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            running_g_loss += g_loss.item()\n",
    "            \n",
    "            ## -------------------\n",
    "            ## Train discriminator\n",
    "            ## -------------------\n",
    "            \n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            validity_real = discriminator(x, y)\n",
    "            d_real_loss = adv_loss(validity_real, valid)\n",
    "            \n",
    "            validity_fake = discriminator(gen_x.detach(), gen_y)\n",
    "            d_fake_loss = adversarial_loss(validity_fake, fake)\n",
    "            \n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "            \n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            running_d_loss += d_loss.item()\n",
    "            \n",
    "        epoch_g_loss = running_g_loss / len(dataloader)\n",
    "        epoch_d_loss = running_d_loss / len(dataloader)\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            generator.eval()\n",
    "\n",
    "            save_reconstruction(generator,\n",
    "                                generator_latent_dim,\n",
    "                                n_classes,\n",
    "                                epoch,\n",
    "                                device)\n",
    "            generator.train()\n",
    "\n",
    "            \n",
    "        print('G Loss: {:.4f} D Loss: {:.4f}'.format(epoch_g_loss,\n",
    "                                                     epoch_d_loss))\n",
    "        \n",
    "        model_loss['generator'].append(epoch_g_loss)\n",
    "        model_loss['discriminator'].append(epoch_d_loss)\n",
    "    \n",
    "    plot_loss(model_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n",
      "----------\n",
      "G Loss: 5.6697 D Loss: 0.1136\n",
      "Epoch 1/199\n",
      "----------\n",
      "G Loss: 6.5506 D Loss: 0.0793\n",
      "Epoch 2/199\n",
      "----------\n",
      "G Loss: 7.2665 D Loss: 0.0525\n",
      "Epoch 3/199\n",
      "----------\n",
      "G Loss: 8.4182 D Loss: 0.0561\n",
      "Epoch 4/199\n",
      "----------\n",
      "G Loss: 9.0557 D Loss: 0.0420\n",
      "Epoch 5/199\n",
      "----------\n",
      "G Loss: 8.6589 D Loss: 0.0711\n",
      "Epoch 6/199\n",
      "----------\n",
      "G Loss: 8.3463 D Loss: 0.0476\n",
      "Epoch 7/199\n",
      "----------\n",
      "G Loss: 6.5218 D Loss: 0.0741\n",
      "Epoch 8/199\n",
      "----------\n",
      "G Loss: 7.1994 D Loss: 0.0534\n",
      "Epoch 9/199\n",
      "----------\n",
      "G Loss: 7.8340 D Loss: 0.0583\n",
      "Epoch 10/199\n",
      "----------\n",
      "G Loss: 6.9754 D Loss: 0.0698\n",
      "Epoch 11/199\n",
      "----------\n",
      "G Loss: 6.3045 D Loss: 0.0675\n",
      "Epoch 12/199\n",
      "----------\n",
      "G Loss: 6.5394 D Loss: 0.0666\n",
      "Epoch 13/199\n",
      "----------\n",
      "G Loss: 5.1926 D Loss: 0.1059\n",
      "Epoch 14/199\n",
      "----------\n",
      "G Loss: 4.5713 D Loss: 0.1082\n",
      "Epoch 15/199\n",
      "----------\n",
      "G Loss: 4.9372 D Loss: 0.0937\n",
      "Epoch 16/199\n",
      "----------\n",
      "G Loss: 5.2146 D Loss: 0.0852\n",
      "Epoch 17/199\n",
      "----------\n",
      "G Loss: 5.0051 D Loss: 0.0901\n",
      "Epoch 18/199\n",
      "----------\n",
      "G Loss: 5.1861 D Loss: 0.0888\n",
      "Epoch 19/199\n",
      "----------\n",
      "G Loss: 4.6891 D Loss: 0.0897\n",
      "Epoch 20/199\n",
      "----------\n",
      "G Loss: 4.7151 D Loss: 0.0966\n",
      "Epoch 21/199\n",
      "----------\n",
      "G Loss: 4.7696 D Loss: 0.0817\n",
      "Epoch 22/199\n",
      "----------\n",
      "G Loss: 4.9468 D Loss: 0.0956\n",
      "Epoch 23/199\n",
      "----------\n",
      "G Loss: 5.0749 D Loss: 0.0803\n",
      "Epoch 24/199\n",
      "----------\n",
      "G Loss: 4.6441 D Loss: 0.0945\n",
      "Epoch 25/199\n",
      "----------\n",
      "G Loss: 4.8646 D Loss: 0.0913\n",
      "Epoch 26/199\n",
      "----------\n",
      "G Loss: 4.6722 D Loss: 0.0909\n",
      "Epoch 27/199\n",
      "----------\n",
      "G Loss: 4.2952 D Loss: 0.1120\n",
      "Epoch 28/199\n",
      "----------\n",
      "G Loss: 4.4580 D Loss: 0.0981\n",
      "Epoch 29/199\n",
      "----------\n",
      "G Loss: 4.4271 D Loss: 0.0964\n",
      "Epoch 30/199\n",
      "----------\n",
      "G Loss: 4.4948 D Loss: 0.1118\n",
      "Epoch 31/199\n",
      "----------\n",
      "G Loss: 4.5577 D Loss: 0.1121\n",
      "Epoch 32/199\n",
      "----------\n",
      "G Loss: 4.1853 D Loss: 0.1237\n",
      "Epoch 33/199\n",
      "----------\n",
      "G Loss: 4.1800 D Loss: 0.1171\n",
      "Epoch 34/199\n",
      "----------\n",
      "G Loss: 4.2192 D Loss: 0.1008\n",
      "Epoch 35/199\n",
      "----------\n",
      "G Loss: 4.3668 D Loss: 0.0994\n",
      "Epoch 36/199\n",
      "----------\n",
      "G Loss: 4.5795 D Loss: 0.1082\n",
      "Epoch 37/199\n",
      "----------\n",
      "G Loss: 4.4162 D Loss: 0.1113\n",
      "Epoch 38/199\n",
      "----------\n",
      "G Loss: 4.3750 D Loss: 0.1167\n",
      "Epoch 39/199\n",
      "----------\n",
      "G Loss: 4.5358 D Loss: 0.1042\n",
      "Epoch 40/199\n",
      "----------\n",
      "G Loss: 4.4172 D Loss: 0.1121\n",
      "Epoch 41/199\n",
      "----------\n",
      "G Loss: 4.5201 D Loss: 0.1046\n",
      "Epoch 42/199\n",
      "----------\n",
      "G Loss: 4.7922 D Loss: 0.1083\n",
      "Epoch 43/199\n",
      "----------\n",
      "G Loss: 4.8160 D Loss: 0.1108\n",
      "Epoch 44/199\n",
      "----------\n",
      "G Loss: 4.3443 D Loss: 0.1373\n",
      "Epoch 45/199\n",
      "----------\n",
      "G Loss: 4.3887 D Loss: 0.1213\n",
      "Epoch 46/199\n",
      "----------\n",
      "G Loss: 4.1990 D Loss: 0.1404\n",
      "Epoch 47/199\n",
      "----------\n",
      "G Loss: 3.8578 D Loss: 0.1493\n",
      "Epoch 48/199\n",
      "----------\n",
      "G Loss: 4.1240 D Loss: 0.1316\n",
      "Epoch 49/199\n",
      "----------\n",
      "G Loss: 4.0254 D Loss: 0.1358\n",
      "Epoch 50/199\n",
      "----------\n",
      "G Loss: 3.9085 D Loss: 0.1432\n",
      "Epoch 51/199\n",
      "----------\n",
      "G Loss: 4.1731 D Loss: 0.1438\n",
      "Epoch 52/199\n",
      "----------\n",
      "G Loss: 3.8359 D Loss: 0.1509\n",
      "Epoch 53/199\n",
      "----------\n",
      "G Loss: 3.8009 D Loss: 0.1569\n",
      "Epoch 54/199\n",
      "----------\n",
      "G Loss: 4.4360 D Loss: 0.1265\n",
      "Epoch 55/199\n",
      "----------\n",
      "G Loss: 3.5549 D Loss: 0.1610\n",
      "Epoch 56/199\n",
      "----------\n",
      "G Loss: 3.5937 D Loss: 0.1748\n",
      "Epoch 57/199\n",
      "----------\n",
      "G Loss: 3.7283 D Loss: 0.1631\n",
      "Epoch 58/199\n",
      "----------\n",
      "G Loss: 4.1653 D Loss: 0.1555\n",
      "Epoch 59/199\n",
      "----------\n",
      "G Loss: 3.5157 D Loss: 0.1802\n",
      "Epoch 60/199\n",
      "----------\n",
      "G Loss: 3.5679 D Loss: 0.1903\n",
      "Epoch 61/199\n",
      "----------\n",
      "G Loss: 4.0251 D Loss: 0.1751\n",
      "Epoch 62/199\n",
      "----------\n",
      "G Loss: 3.4901 D Loss: 0.1854\n",
      "Epoch 63/199\n",
      "----------\n",
      "G Loss: 3.5239 D Loss: 0.1724\n",
      "Epoch 64/199\n",
      "----------\n",
      "G Loss: 3.4821 D Loss: 0.1843\n",
      "Epoch 65/199\n",
      "----------\n",
      "G Loss: 3.4173 D Loss: 0.1940\n",
      "Epoch 66/199\n",
      "----------\n",
      "G Loss: 3.1856 D Loss: 0.2100\n",
      "Epoch 67/199\n",
      "----------\n",
      "G Loss: 3.2573 D Loss: 0.2061\n",
      "Epoch 68/199\n",
      "----------\n",
      "G Loss: 3.1083 D Loss: 0.2142\n",
      "Epoch 69/199\n",
      "----------\n",
      "G Loss: 3.1961 D Loss: 0.2131\n",
      "Epoch 70/199\n",
      "----------\n",
      "G Loss: 3.2073 D Loss: 0.2191\n",
      "Epoch 71/199\n",
      "----------\n",
      "G Loss: 3.1325 D Loss: 0.2205\n",
      "Epoch 72/199\n",
      "----------\n",
      "G Loss: 3.0564 D Loss: 0.2341\n",
      "Epoch 73/199\n",
      "----------\n",
      "G Loss: 3.2410 D Loss: 0.2127\n",
      "Epoch 74/199\n",
      "----------\n",
      "G Loss: 3.0900 D Loss: 0.2184\n",
      "Epoch 75/199\n",
      "----------\n",
      "G Loss: 2.9710 D Loss: 0.2403\n",
      "Epoch 76/199\n",
      "----------\n",
      "G Loss: 3.1052 D Loss: 0.2427\n",
      "Epoch 77/199\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b85eb8c52a29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mMODEL_HYPERPARAMETERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'generator_latent_dim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mTRAIN_PARAMETERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_classes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             DEVICE)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-4ea82c06ab8c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, dataloader, generator, optimizer_G, discriminator, optimizer_D, adv_loss, generator_latent_dim, n_classes, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(TRAIN_PARAMETERS['epochs'],\n",
    "            dataloader,\n",
    "            generator,\n",
    "            optimizer_G,\n",
    "            discriminator,\n",
    "            optimizer_D,\n",
    "            adversarial_loss,\n",
    "            MODEL_HYPERPARAMETERS['generator_latent_dim'],\n",
    "            TRAIN_PARAMETERS['num_classes'],\n",
    "            DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
