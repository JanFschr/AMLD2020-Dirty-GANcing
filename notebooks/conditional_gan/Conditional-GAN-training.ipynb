{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional GAN\n",
    "\n",
    "**Purpose**: This notebook provides a walk through the process of training a Conditional GAN to generate digits on the MNIST dataset. Refer to the paper https://arxiv.org/abs/1411.1784 for a full detailed explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.pylab import plt\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variable declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PARAMETERS = {'batch_size': 128,\n",
    "                    'num_classes': 10,\n",
    "                    'img_shape': (1,28,28),\n",
    "                    'epochs': 200,\n",
    "                    'learning_rate': 0.0002}\n",
    "\n",
    "MODEL_HYPERPARAMETERS = {'generator_latent_dim': 100}\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size,\n",
    "                   img_shape):\n",
    "    \n",
    "    img_size = img_shape[1:]\n",
    "    \n",
    "    dataset = datasets.MNIST(root='./data/MNIST',\n",
    "                             train=True,\n",
    "                             download=True,\n",
    "                             transform=transforms.Compose([transforms.Resize(img_size),\n",
    "                                                           transforms.ToTensor(),\n",
    "                                                           transforms.Normalize([0.5], [0.5])]))\n",
    "    \n",
    "    return torch.utils.data.DataLoader(dataset,\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_dataloader(TRAIN_PARAMETERS['batch_size'],\n",
    "                            TRAIN_PARAMETERS['img_shape'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative Adversarial Nets consist on two components competing against each other in a min-max game. These models are:\n",
    "\n",
    "- **Discriminator:** Estimates the probability of a sample coming from the training data or not.\n",
    "- **Generator:** Captures the data distribution generating samples accordingly.\n",
    "\n",
    "Both models play a min max game; the objective of the generator is to fool the discriminator by generating more realistic samples. On the other hand, the discriminator's objective is to identify the samples generated by the generator.\n",
    "\n",
    "Translating these min max game to mathematics, we adjust the Generator's parameters to minimize $log(1-D(G(z))$ and the Discriminator's parameters to minimize $log(D(x))$. Thus, resulting in the following formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/gan_training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Conditional GAN framework adds to both, the input of the discriminator and the generator, some extra information y (note that the aforementioned formula will need to include the condition on y). This extra information often times is the sample class. The model architecture is depicted in the next figure. As it can be seen in the Figure, the generator concatenatese the sampling from z with the input y. Likewise, the discriminator concatenates x with the input y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/conditional_gan_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 img_shape,\n",
    "                 latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(n_classes, n_classes)\n",
    "        self.img_shape = img_shape\n",
    "        \n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim + n_classes, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        gen_input = torch.cat((self.label_emb(labels), noise), -1)\n",
    "        img = self.model(gen_input)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 img_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.label_embedding = nn.Embedding(n_classes,\n",
    "                                            n_classes)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_classes + int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1)\n",
    "        validity = self.model(d_in)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_model(num_classes,\n",
    "                        img_shape,\n",
    "                        latent_dim,\n",
    "                        lr,\n",
    "                        device):\n",
    "    ''' Returns the generator model and its optimizer '''\n",
    "    \n",
    "    generator = Generator(num_classes,\n",
    "                          img_shape,\n",
    "                          latent_dim)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(generator.parameters(),\n",
    "                                 lr=lr)\n",
    "    \n",
    "    return generator.to(device), optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator_model(num_classes,\n",
    "                            img_shape,\n",
    "                            lr,\n",
    "                            device):\n",
    "    ''' Returns the discriminator model and its optimizer '''\n",
    "    \n",
    "    discriminator = Discriminator(num_classes,\n",
    "                                  img_shape)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(discriminator.parameters(),\n",
    "                                 lr=lr)\n",
    "    \n",
    "    return discriminator.to(device), optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator, optimizer_G = get_generator_model(TRAIN_PARAMETERS['num_classes'],\n",
    "                                             TRAIN_PARAMETERS['img_shape'],\n",
    "                                             MODEL_HYPERPARAMETERS['generator_latent_dim'],\n",
    "                                             TRAIN_PARAMETERS['learning_rate'],\n",
    "                                             DEVICE)\n",
    "discriminator, optimizer_D = get_discriminator_model(TRAIN_PARAMETERS['num_classes'],\n",
    "                                                     TRAIN_PARAMETERS['img_shape'],\n",
    "                                                     TRAIN_PARAMETERS['learning_rate'],\n",
    "                                                     DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adversarial_loss():\n",
    "    ''' Returns the adversarial loss '''\n",
    "    \n",
    "    return torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = get_adversarial_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_reconstruction(generator,\n",
    "                        generator_latent_dim,\n",
    "                        n_row,\n",
    "                        epoch_n,\n",
    "                        device):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "\n",
    "    # Create the saving directory\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    # Sample noise\n",
    "    z = torch.FloatTensor(np.random.normal(0, 1, (n_row ** 2, generator_latent_dim))).to(device)\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
    "    labels = torch.LongTensor(labels).to(device)\n",
    "    gen_imgs = generator(z, labels)\n",
    "    save_image(gen_imgs.data, \"results/%d.png\" % epoch_n, nrow=n_row, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(loss_dict):\n",
    "    ''' Plots the loss evolution of the discriminator and generator '''\n",
    "    \n",
    "    for component_name, component_loss in loss_dict.items():\n",
    "        \n",
    "        plt.plot(component_loss, label=component_name)\n",
    "    \n",
    "    plt.title('Loss plot')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs,\n",
    "                dataloader,\n",
    "                generator,\n",
    "                optimizer_G,\n",
    "                discriminator,\n",
    "                optimizer_D,\n",
    "                adv_loss,\n",
    "                generator_latent_dim,\n",
    "                n_classes,\n",
    "                device):\n",
    "    ''' Trains the GAN model '''\n",
    "    \n",
    "    model_loss = {'generator': [], 'discriminator': []}\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        running_g_loss = running_d_loss = 0\n",
    "        \n",
    "        for x, y in dataloader:\n",
    "            \n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            batch_size = x.shape[0]\n",
    "            \n",
    "            valid = torch.FloatTensor(batch_size, 1).fill_(1.0).to(device)\n",
    "            fake = torch.FloatTensor(batch_size, 1).fill_(0.0).to(device)\n",
    "        \n",
    "            ## ---------------\n",
    "            ## Train generator\n",
    "            ## ---------------\n",
    "            \n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            # Sample noise and labels\n",
    "            z = torch.FloatTensor(np.random.normal(0, 1, (batch_size, generator_latent_dim))).to(device)\n",
    "            gen_y = torch.LongTensor(np.random.randint(0, n_classes, batch_size)).to(device)\n",
    "            gen_x = generator(z, gen_y)\n",
    "\n",
    "            validity = discriminator(gen_x, gen_y)\n",
    "            g_loss = adv_loss(validity, valid)\n",
    "            \n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            running_g_loss += g_loss.item()\n",
    "            \n",
    "            ## -------------------\n",
    "            ## Train discriminator\n",
    "            ## -------------------\n",
    "            \n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            validity_real = discriminator(x, y)\n",
    "            d_real_loss = adv_loss(validity_real, valid)\n",
    "            \n",
    "            validity_fake = discriminator(gen_x.detach(), gen_y)\n",
    "            d_fake_loss = adversarial_loss(validity_fake, fake)\n",
    "            \n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "            \n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            running_d_loss += d_loss.item()\n",
    "            \n",
    "        epoch_g_loss = running_g_loss / len(dataloader)\n",
    "        epoch_d_loss = running_d_loss / len(dataloader)\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            generator.eval()\n",
    "\n",
    "            save_reconstruction(generator,\n",
    "                                generator_latent_dim,\n",
    "                                n_classes,\n",
    "                                epoch,\n",
    "                                device)\n",
    "            generator.train()\n",
    "\n",
    "            \n",
    "        print('G Loss: {:.4f} D Loss: {:.4f}'.format(epoch_g_loss,\n",
    "                                                     epoch_d_loss))\n",
    "        \n",
    "        model_loss['generator'].append(epoch_g_loss)\n",
    "        model_loss['discriminator'].append(epoch_d_loss)\n",
    "    \n",
    "    plot_loss(model_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n",
      "----------\n",
      "G Loss: 0.9463 D Loss: 0.0162\n",
      "Epoch 1/199\n",
      "----------\n",
      "G Loss: 0.9713 D Loss: 0.0108\n",
      "Epoch 2/199\n",
      "----------\n",
      "G Loss: 0.9548 D Loss: 0.0149\n",
      "Epoch 3/199\n",
      "----------\n",
      "G Loss: 0.9668 D Loss: 0.0116\n",
      "Epoch 4/199\n",
      "----------\n",
      "G Loss: 0.9582 D Loss: 0.0136\n",
      "Epoch 5/199\n",
      "----------\n",
      "G Loss: 0.9562 D Loss: 0.0151\n",
      "Epoch 6/199\n",
      "----------\n",
      "G Loss: 0.9551 D Loss: 0.0152\n",
      "Epoch 7/199\n",
      "----------\n",
      "G Loss: 0.9379 D Loss: 0.0201\n",
      "Epoch 8/199\n",
      "----------\n",
      "G Loss: 0.9322 D Loss: 0.0221\n",
      "Epoch 9/199\n",
      "----------\n",
      "G Loss: 0.9361 D Loss: 0.0209\n",
      "Epoch 10/199\n",
      "----------\n",
      "G Loss: 0.9337 D Loss: 0.0224\n",
      "Epoch 11/199\n",
      "----------\n",
      "G Loss: 0.9207 D Loss: 0.0266\n",
      "Epoch 12/199\n",
      "----------\n",
      "G Loss: 0.9156 D Loss: 0.0281\n",
      "Epoch 13/199\n",
      "----------\n",
      "G Loss: 0.9116 D Loss: 0.0299\n",
      "Epoch 14/199\n",
      "----------\n",
      "G Loss: 0.8936 D Loss: 0.0349\n",
      "Epoch 15/199\n",
      "----------\n",
      "G Loss: 0.8949 D Loss: 0.0336\n",
      "Epoch 16/199\n",
      "----------\n",
      "G Loss: 0.8805 D Loss: 0.0393\n",
      "Epoch 17/199\n",
      "----------\n",
      "G Loss: 0.8670 D Loss: 0.0432\n",
      "Epoch 18/199\n",
      "----------\n",
      "G Loss: 0.8766 D Loss: 0.0395\n",
      "Epoch 19/199\n",
      "----------\n",
      "G Loss: 0.8744 D Loss: 0.0407\n",
      "Epoch 20/199\n",
      "----------\n",
      "G Loss: 0.8628 D Loss: 0.0444\n",
      "Epoch 21/199\n",
      "----------\n",
      "G Loss: 0.8540 D Loss: 0.0477\n",
      "Epoch 22/199\n",
      "----------\n",
      "G Loss: 0.8524 D Loss: 0.0479\n",
      "Epoch 23/199\n",
      "----------\n",
      "G Loss: 0.8444 D Loss: 0.0500\n",
      "Epoch 24/199\n",
      "----------\n",
      "G Loss: 0.8491 D Loss: 0.0488\n",
      "Epoch 25/199\n",
      "----------\n",
      "G Loss: 0.8433 D Loss: 0.0506\n",
      "Epoch 26/199\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "train_model(TRAIN_PARAMETERS['epochs'],\n",
    "            dataloader,\n",
    "            generator,\n",
    "            optimizer_G,\n",
    "            discriminator,\n",
    "            optimizer_D,\n",
    "            adversarial_loss,\n",
    "            MODEL_HYPERPARAMETERS['generator_latent_dim'],\n",
    "            TRAIN_PARAMETERS['num_classes'],\n",
    "            DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
